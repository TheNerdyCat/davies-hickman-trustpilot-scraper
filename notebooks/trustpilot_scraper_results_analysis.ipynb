{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc736bbf-dc22-4bb6-a720-913a495ba9ef",
   "metadata": {},
   "source": [
    "# TrustPilot Scraper | Results Analysis\n",
    "\n",
    "This notebook conducts some data cleaning, filtering and analysis on the results of the data scraped by the TrustPilot scraper developed in the previous notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9718ad3-818e-41ac-bfda-4db84cf54cb0",
   "metadata": {},
   "source": [
    "## 0.0 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394fcaf-8156-4dfb-a037-3578e84eaae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation & stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4760fe-7625-476b-98ca-c082f7c886c7",
   "metadata": {},
   "source": [
    "## 1.0 Setup Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a060d62f-6238-4aed-ab11-4cfcae62168c",
   "metadata": {},
   "source": [
    "### 1.1 Local paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aca0d4-601e-4b5f-a651-5a6dcbd1aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks_dir_path = os.getcwd()\n",
    "repo_dir_path = notebooks_dir_path.replace(\"/notebooks\", \"\")\n",
    "data_dir_path = os.path.join(repo_dir_path, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f8e0b-1c74-40d4-a7e0-fab60a2b1852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local data paths\n",
    "category_dirs = os.listdir(data_dir_path)\n",
    "category_dirs = [directory for directory in category_dirs if not directory.startswith(\".\")]\n",
    "print(f\"Categories scraped:\")\n",
    "\n",
    "# Category paths\n",
    "category_dir_paths = [os.path.join(data_dir_path, directory) for directory in category_dirs]\n",
    "category_df_paths = [os.path.join(directory, \"companies_df_full.csv\") for directory in category_dir_paths]\n",
    "category_df_paths = [\n",
    "    os.path.join(directory, \"companies_df_full.csv\") for directory in category_dir_paths \\\n",
    "    if os.path.exists(os.path.join(directory, \"companies_df_full.csv\"))\n",
    "]\n",
    "\n",
    "# Read in data\n",
    "df_dict = {}\n",
    "for category_df_path in category_df_paths:\n",
    "    category_name = category_df_path.split(\"/\")[7]\n",
    "    print(category_name)\n",
    "    \n",
    "    # Read in df\n",
    "    data = []\n",
    "    \n",
    "    with open(category_df_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "    \n",
    "        try:\n",
    "            for row in reader:\n",
    "                data.append(row)\n",
    "        except csv.Error as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "    \n",
    "    # Convert the list of lists (data) to a pandas DataFrame\n",
    "    category_df = pd.DataFrame(data)\n",
    "\n",
    "    category_df.columns = category_df.iloc[0]\n",
    "    category_df = category_df[1:]  # Skip the first row since it's now the header\n",
    "    \n",
    "    df_dict[category_name] = category_df\n",
    "    df_clean_path = os.path.join(data_dir_path, category_name, \"clean_categories_data.csv\")\n",
    "    category_df.to_csv(df_clean_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8dd15-bdfe-4684-989b-a2f5605d1a9e",
   "metadata": {},
   "source": [
    "## 2.0 Category data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed843b75-fc48-414b-8662-bdec918d77c3",
   "metadata": {},
   "source": [
    "### 2.1 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d7e60-47fc-4054-95d9-1fdeb8778bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions for each raw category df\n",
    "for key in df_dict.keys():\n",
    "    print(f\"{key}: {df_dict[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c103a-6a9e-459e-b6de-5ca48d208ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for df_sub_name in df_dict.keys():\n",
    "    df_sub = df_dict[df_sub_name]\n",
    "    df_sub[\"category\"] = df_sub_name\n",
    "    df = pd.concat(\n",
    "        [df, df_sub],\n",
    "        ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164bfda-2c6b-469b-a305-7565e00c1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'-'*100}\\nNumber of None records by column\\n{'-'*100}\\n{df.isnull().sum() / len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22e870-3ac7-433a-8135-b5b1df5ea5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null rows\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert all int to columns\n",
    "for col_int in [\"company_score\", \"num_reviews\", \"categories_page\", \"score\"]:\n",
    "    df[col_int] = df[col_int].astype(float)\n",
    "\n",
    "# Convert all str columns to lower\n",
    "for col_str in [\"company_name\", \"address\", \"review\"]:\n",
    "    df[f\"{col_str}_clean\"] = df[col_str].apply(lambda x: x.lower() if x is not None else \"\")\n",
    "    \n",
    "# Clean is_uk column\n",
    "df[\"is_uk\"] = df.groupby(\"company_name_clean\")[\"address_clean\"].transform(\n",
    "    lambda x: any((\"uk\" in str(a) or \"united kingdom\" in str(a)) for a in x)\n",
    ")\n",
    "# Find most common address for each company - that isn't blank\n",
    "most_common_address = df.groupby(\"company_name_clean\")[\"address_clean\"].agg(\n",
    "    lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
    ").reset_index()\n",
    "most_common_address.columns = [\"company_name_clean\", \"most_common_address_clean\"]\n",
    "most_common_address[\"most_common_address_clean\"] = most_common_address[\"most_common_address_clean\"].apply(\n",
    "    lambda x: x if (x is not None and x != \"\") else \"united kingdom\"\n",
    ")\n",
    "# Merge and replace the most common address\n",
    "df = pd.merge(df, most_common_address, on='company_name_clean', how='left')\n",
    "df[\"address_clean\"] = df[\"most_common_address_clean\"]\n",
    "df = df.drop(\"most_common_address_clean\", axis=1)\n",
    "\n",
    "# Detect keywords in reviews\n",
    "keywords = ['whatsapp', 'whats app', 'whats app', 'message', 'texted', 'text', 'sms', 'messaged']\n",
    "df[\"review_clean\"] = df[\"review\"].apply(lambda x: x.lower() if x is not None else \"\")\n",
    "df[\"contains_keyword\"] = df[\"review_clean\"].str.contains('|'.join(map(re.escape, keywords)))\n",
    "\n",
    "# Get number of reviews in df\n",
    "num_reviews_in_df = pd.DataFrame(\n",
    "    df.groupby(\"company_name_clean\")[\"review\"].count()\n",
    ").rename(columns={\"review\": \"num_reviews_in_df\"})\n",
    "\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    num_reviews_in_df,\n",
    "    on=\"company_name_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"pct_reviews_scraped\"] = df[\"num_reviews_in_df\"] / df[\"num_reviews\"]\n",
    "\n",
    "# Get pct of reviews that contain keyword\n",
    "num_contains_keyword = pd.DataFrame(\n",
    "    df.groupby(\"company_name_clean\")[\"contains_keyword\"].sum()\n",
    ").rename(columns={\"contains_keyword\": \"num_contains_keyword\"})\n",
    "\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    num_contains_keyword,\n",
    "    on=\"company_name_clean\",\n",
    "    how=\"left\"\n",
    ")\n",
    "df[\"pct_contains_keyword\"] = df[\"num_contains_keyword\"] / df[\"num_reviews_in_df\"]\n",
    "\n",
    "df = df.loc[df.is_uk == True]\n",
    "\n",
    "# Run sentiment analysis on review\n",
    "df[\"sentiment\"] = df[\"review\"].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "# Classify sentiments into positive, neutral, or negative\n",
    "df[\"sentiment_class\"] = df[\"sentiment\"].apply(lambda x: \"positive\" if x[\"compound\"] >= 0.05 else (\"negative\" if x[\"compound\"] <= -0.05 else \"neutral\"))\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e977d-42a0-4dd5-a2d7-48086f575cfc",
   "metadata": {},
   "source": [
    "### 2.2 Category stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d92a3-42b2-460b-8d6a-9aac8e23b9ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of companies: {df.company_name_clean.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690a6d0-2341-4572-ba99-438739b35c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of companies by category\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot 1 - Number of companies by category\n",
    "sns.barplot(\n",
    "    pd.DataFrame(\n",
    "        df.groupby(\"category\")[\"company_name_clean\"].nunique()\n",
    "    ).rename(columns={\"company_name_clean\": \"num_companies\"}).sort_values(\"num_companies\", ascending=False),\n",
    "    x=\"num_companies\",\n",
    "    y=\"category\",\n",
    "    ax=axes[0] \n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Number of companies by category\")\n",
    "axes[0].set_xlabel(\"Number of companies\")\n",
    "axes[0].set_ylabel(\"Category\")\n",
    "axes[0].grid(axis=\"x\")\n",
    "\n",
    "# Plot 2 - Number of reviews by category\n",
    "sns.barplot(\n",
    "    pd.DataFrame(\n",
    "        df.groupby(\"category\")[\"review\"].count()\n",
    "    ).rename(columns={\"review\": \"num_reviews\"}).sort_values(\"num_reviews\", ascending=False),\n",
    "    x=\"num_reviews\",\n",
    "    y=\"category\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"Number of reviews by category\")\n",
    "axes[1].set_xlabel(\"Number of reviews\")\n",
    "axes[1].set_ylabel(\"Category\")\n",
    "axes[1].grid(axis=\"x\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74242e4-c27f-42bf-aa44-6af0323c65fe",
   "metadata": {},
   "source": [
    "### 2.3 Keyword stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc166f-d912-47f7-bb04-b92f3050ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reviews that contain keyword\n",
    "sns.histplot(\n",
    "    df[[\"company_name_clean\", \"pct_contains_keyword\"]].drop_duplicates(),\n",
    "    x=\"pct_contains_keyword\"\n",
    ")\n",
    "\n",
    "plt.title(\"Percentage of reviews that contain a keyword\")\n",
    "plt.xlabel(\"Percentage of reviews\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ca8d7-6eaa-4055-a4fc-6d6ec0860a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis on each review\n",
    "df[\"sentiment\"] = df[\"review\"].apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x))\n",
    "# Classify sentiments into positive, neutral, or negative\n",
    "df[\"sentiment_class\"] = df[\"sentiment\"].apply(lambda x: \"positive\" if x[\"compound\"] >= 0.05 else (\"negative\" if x[\"compound\"] <= -0.05 else \"neutral\"))\n",
    "# Drop the intermediate sentiment column if needed\n",
    "df = df.drop(columns=[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d142bc0-950e-43a2-aa50-6897c585666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"full_categories_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550f39e-b62c-400c-a676-c751c487d850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78422c-0d25-4f01-8b2e-f8bdd96d86b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1650e98-6332-48c3-9c62-6a3439e7bd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d37368-f08c-45fb-b37e-366219d1e012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795777d-eb59-478a-8c6f-a064a1d9ad85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddf2bc-d66e-40fe-8437-b9c1d08a45fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3a2b8-5725-4f21-8828-f5d71ff22cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fad2a-4a2e-469a-89f2-30f1b9ab22ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "davies-hickman-trustpilot-scraper",
   "language": "python",
   "name": "davies-hickman-trustpilot-scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
